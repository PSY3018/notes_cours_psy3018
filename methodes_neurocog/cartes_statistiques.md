---
jupytext:
  cell_metadata_filter: -all
  formats: md:myst
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.10.3
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---
(cartes-statistiques-chapitre)=
# Cartes statistiques

<table>
  <tr>
    <td align="center">
      <a href="https://github.com/elisabethloranger">
        <img src="https://avatars.githubusercontent.com/u/90270981?v=4?s=100" width="100px;" alt=""/>
        <br /><sub><b>√âlisabeth Loranger</b></sub>
      </a>
      <br />
        <a title="Contenu">ü§î</a>
    </td>
    <td align="center">
      <a href="https://github.com/pbellec">
        <img src="https://avatars.githubusercontent.com/u/1670887?v=4?s=100" width="100px;" alt=""/>
        <br /><sub><b>Pierre bellec</b></sub>
      </a>
      <br />
        <a title="Contenu">ü§î</a>
    </td>
  </tr>
</table>

```{warning}
Ce chapitre est en cours de d√©veloppement. Il se peut que l'information soit incompl√®te, ou sujette √† changement.
```
## Objectifs du cours

On va parler du mod√®le de r√©gression pour g√©n√©rer des cartes statistiques c√©r√©brales de groupe. Les statistiques de groupe permettent de combiner les mesures du cerveau de plusieurs individus et ainsi de contraster des groupes (ex. groupe de personnes jeunes et groupe de personnes √¢g√©es) ou bien de tester l'association avec une variable continue (ex. l'√¢ge).

Les objectifs sp√©cifiques du cours sont les suivants :
 * R√©gression lin√©aire.
 * Le mod√®le lin√©aire g√©n√©ral.
 * Comparaisons multiples.

## R√©gression lin√©aire

### Variables
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
# Importer les librairies
import numpy as np
import matplotlib.pyplot as plt
from nilearn import datasets
from nilearn.input_data import NiftiMasker
from nilearn.image import get_data

# Charge les donn√©es
n_subjects = 100  
oasis_dataset = datasets.fetch_oasis_vbm(n_subjects=n_subjects)
gray_matter_map_filenames = oasis_dataset.gray_matter_maps
age = oasis_dataset.ext_vars['age'].astype(float)
sex = oasis_dataset.ext_vars['mf'] == b'F'

# On convertit les donn√©es en pandas dataframe
# Deux voxels int√©ressants ont √©t√© s√©lectionn√©s
import pandas as pd
coords = np.array([[ 29.,  10.,   4.], [-19.,   8., -11.]])
colors = ['blue', 'olive']

from nilearn import input_data
masker = input_data.NiftiSpheresMasker(coords)
gm = masker.fit_transform(gray_matter_map_filenames)
subject_label = [f'sub-{num}' for num in range(n_subjects)]
df = pd.DataFrame({
    "subject_label": subject_label,
    "age": age,
    "sexe": oasis_dataset.ext_vars['mf'],
    "MG1": gm[:, 0],
    "MG2": gm[:, 1]
    })

df["sexe"] = df["sexe"].replace([b'F', b'M'], value=['femelle', 'male'])

# On g√©n√®re la Figure
from nilearn import plotting
import seaborn as sns
fig = plt.figure(figsize=(24, 14))

for i in range(0, 6):        
    nx = np.floor_divide(i, 3)
    ny = np.remainder(i, 3)
    ax = plt.subplot2grid((2, 5), (nx, ny), colspan=1)
    roi_img = plotting.plot_anat(
        gray_matter_map_filenames[i], cut_coords=[coords[nx][2]], figure=fig,
        axes=ax, display_mode='z', colorbar=False)
    roi_img.add_markers([coords[nx]], colors[nx], 100)

sns.set_theme(style="darkgrid")
ax = plt.subplot2grid((2, 5), (0, 3), colspan=2)
sns.histplot(
    df["MG1"], ax=ax, binwidth=0.05, binrange=[0, 1], stat='frequency')

ax = plt.subplot2grid((2, 5), (1, 3), colspan=2)
sns.histplot(
    df["MG2"], ax=ax, binwidth=0.05, binrange=[0, 1], stat='frequency')

from myst_nb import glue
glue("vbm-distribution-fig", fig, display=False)
```
```{glue:figure} vbm-distribution-fig
:figwidth: 800px
:name: vbm-distribution-fig
La position de deux voxels est illustr√©e avec un cercle bleu (haut) et olive (bas), de mani√®re superpos√©e avec des cartes de densit√© de mati√®re grise pour diff√©rents sujets du jeu de donn√©es OASIS ([Marcus et al., 2010](https://dx.doi.org/10.1162%2Fjocn.2009.21407)). √Ä droite, un histograme repr√©sente la distribution de la densit√© de mati√®re grise pour le voxel correspondant, au travers de 100 sujets. Cette figure est adapt√©e d'un tutoriel de la librairie [nilearn](https://nilearn.github.io/auto_examples/05_glm_second_level/plot_oasis.html#sphx-glr-auto-examples-05-glm-second-level-plot-oasis-py) (cliquer sur + pour voir le code). Cette figure est distribu√©e sous license [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```
Les concepts pr√©sent√©s dans ce chapitre s‚Äôappliquent √† la plupart des modalit√©s d'imagerie vues dans le cours de fa√ßon plus ou moins identique. Mais afin de rendre les choses plus concr√®tes, nous allons nous int√©resser √† une analyse en morphom√©trie VBM √† l'aide de l'IRM structurelle. Cette analyse utilise le jeu de donn√©es OASIS ([Marcus et al., 2010](https://dx.doi.org/10.1162%2Fjocn.2009.21407)). Des cartes de densit√© de mati√®re grise pour les donn√©es OASIS sont disponibles via la librairie [nilearn](https://nilearn.github.io/modules/generated/nilearn.datasets.fetch_oasis_vbm.html). Pour chaque voxel, on dispose d'une mesure locale de densit√© de mati√®re grise, qui varie entre 0 et 1. Comme toutes les images des 100 participants OASIS utilis√©s dans cet exemple ont √©t√© recal√©es dans un m√™me espace st√©r√©otaxique, on a donc pour chaque voxel une s√©rie de 100 mesures. Il s'agit de notre **variable d√©pendante**, car on va chercher √† expliquer les variations de cette mesure au travers des sujets √† l'aide d'autres variables, dites **pr√©dicteurs**, et on va d√©marrer avec l'√¢ge des participants qui varie de 20 ans √† 90 ans.

### Mod√®le lin√©aire
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
# On r√©organise de DataFrame pour utiliser seaborn
df2 = df.melt(id_vars=["age", "sexe"], value_vars=["MG1", "MG2"], value_name="MG")
fig = sns.lmplot(x="age", y="MG", data=df2, col='variable',
           ci=None, scatter_kws={"s": 50, "alpha": 1})

# On colle la figure dans le jupyter book
from myst_nb import glue
glue("regression-vbm-fig", fig.fig, display=False)           
```
```{glue:figure} regression-vbm-fig
:figwidth: 800px
:name: regression-vbm-fig
 R√©gression lin√©aire, o√π la variable d√©pendante est la densit√© de mati√®re grise pour un voxel, et le pr√©dicteur est l'√¢ge. Les valeurs de densit√© de mati√®re grise proviennent de 100 sujets de la base de donn√©es OASIS ([Marcus et al., 2010](https://dx.doi.org/10.1162%2Fjocn.2009.21407)), et les deux voxels sont pr√©sent√©s dans la {numref}`vbm-distribution-fig` (voxel bleu √† gauche, voxel olive √† droite). La r√©gression lin√©aire est r√©alis√©e √† l'aide de la libraire [seaborn](https://seaborn.pydata.org) (cliquer sur + pour voir le code). Cette figure est distribu√©e sous license [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```
L'id√©e sous-jacente au mod√®le de r√©gression est une √©quation, ou une sorte de loi, qui va pr√©dire la variable d√©pendante, ici la densit√© de mati√®re grise, √† partir des pr√©dicteurs, disons l'age. Mais, contrairement √† une loi physique qui repr√©sente une d√©pendance exacte (dans un certain r√©gime), cette loi ne capture qu'une fraction de la variance de notre mesure. La loi va donc incorporer un bruit, qui repr√©sente toutes les sources de variabilit√© que l'on ne peut pas capturer avec notre relation. La relation math√©matique va prendre la forme suivante:

`densite_matiere_grise = b0 + b1 * age + e`

 * `densite_matiere_grise` est la densit√© de mati√®re grise mesur√©e pour un voxel.
 * `age` est l'√¢ge du participant de recherche.
 * `b0` est une valeur constante, appel√©e en anglais "intercept". Cette valeur est identique pour tous les sujets. Dans ce cas, elle repr√©sentrait la densit√© de mati√®re grise observ√©e √† la naissance (`age=0`), en moyenne sur la population.
 * `b1` est une autre constante, qui dans ce cas mesure la r√©duction de mati√®re grise par ann√©e de vie (en moyenne sur la population).
 * `e` est un bruit de mesure, qui capture toutes les variations de `densite_matiere_grise` que l'on ne peut pas expliquer avec `age`. Typiquement on suppose que la moyenne de `e` dans la population est `0`, et que la variance de `e` est identique pour tous les sujets, √©gale √† $\sigma^2$.

 On ne connait √©videmment pas les coefficients `b0` et `b1`, et on doit utiliser une proc√©dure statistique pour les `estimer`, c'est √† dire deviner (au mieux) leurs valeurs √† partir des donn√©es dont on dispose. Par exemple, pour la r√©gion de couleur `olive` (graphe de droite dans {numref}`regression-vbm-fig`), on voit que l'on perd environ 25% de densit√© entre 20 ans et 90 ans, voir {numref}`regression-vbm-fig`. On perd donc environ 0.35% de densit√© de mati√®re grise par an, soit `b1 ~ -0.0035`. En utilisant cette valeur et en remarquant que la densit√© de mati√®re grise est d'√† peu pr√®s `0.85` √† `20` ans, on en d√©duit que la densit√© √† la naissance devrait √™tre `b0=0.92`. En pratique la proc√©dure statistique va choisir les valeurs `b0` et `b1` pour minimiser l'amplitude des r√©sidus de la r√©gression:

 `residus = densite_matiere_grise - b0 - b1 * age`

 Une fois les coefficients `b0` et `b1` estim√©s, on peut tracer une droite qui repr√©sente les valeurs de densit√© de mati√®re grise pr√©dites √† partir de l'√¢ge des sujets, voir {numref}`regression-vbm-fig`. Si le mod√®le explique beaucoup de la variabilit√© de la variable d√©pendante, les points mesur√©s seront proches de la droite de pr√©diction.

### Analyse massivement univari√©e
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
from nilearn.glm.second_level import make_second_level_design_matrix
design_df = df[["subject_label", "age"]].replace(['femelle', 'male'], value=[0, 1])
design_matrix = make_second_level_design_matrix(
    subject_label,
    design_df
    )
from nilearn.glm.second_level import SecondLevelModel
second_level_model = SecondLevelModel(smoothing_fwhm=5.0)
second_level_model = second_level_model.fit(gray_matter_map_filenames,
                                            design_matrix=design_matrix)
beta0 = second_level_model.compute_contrast(second_level_contrast="intercept", output_type="effect_size")
beta1 = second_level_model.compute_contrast(second_level_contrast="age", output_type="effect_size")

# On g√©n√®re la Figure
from nilearn import plotting
import seaborn as sns
fig = plt.figure(figsize=(24, 14))

ax = plt.subplot2grid((2, 4), (0, 0), colspan=3)
roi_img = plotting.plot_stat_map(
    beta0, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='intercept (b0)')
roi_img.add_markers([coords[1]], colors[1], 100)

ax = plt.subplot2grid((2, 4), (1, 0), colspan=3)
roi_img = plotting.plot_stat_map(
    beta1, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='effet de l\'age (b1)')
roi_img.add_markers([coords[1]], colors[1], 100)

# On colle la figure dans le jupyter book
from myst_nb import glue
glue("b0-b1-fig", fig, display=False)           
```
```{glue:figure} b0-b1-fig
:figwidth: 600px
:name: b0-b1-fig
 Cartes de param√®tres statistiques dans une r√©gression lin√©aire massivement univari√©e. Premi√®re ligne: intercept `b0`, deuxi√®me ligne: effet lin√©aire de l'√¢ge `b1`. Cette figure est adapt√©e d'un tutoriel de la librairie [nilearn](https://nilearn.github.io/auto_examples/05_glm_second_level/plot_oasis.html#sphx-glr-auto-examples-05-glm-second-level-plot-oasis-py) (cliquer sur + pour voir le code). Cette figure est distribu√©e sous license [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```
On a pour l'instant pr√©sent√© le mod√®le de r√©gression pour deux voxels seulement. Mais une carte VBM peut inclure des centaines de milliers de voxels. Les logiciels de neuroimagerie permettent d'effectuer syst√©matiquement une r√©gression lin√©aire pour l'ensemble des voxels, simultan√©ment. Dans ce cas, on estime deux param√®tres pour chaque voxel: `b0` (l'intercept) et `b1` (l'effet de l'√¢ge). On va donc g√©n√©rer deux cartes statistiques s√©par√©es, voir {numref}`b0-b1-fig`. Ces deux cartes r√©capitulent donc des milliers de mod√®les de r√©gression diff√©rents. Comme les r√©gressions effectu√©es √† chaque voxel sont ind√©pendante les unes des autres, on parle de mod√®le univari√©, par opposition √† un mod√®le multivari√© qui cherche √† combiner les valeurs obtenues √† diff√©rents voxels. De plus, comme on fait un tr√®s grand nombre de r√©gressions en m√™me temps, on parle de r√©gression **massivement univari√©e**.

```{admonition} Statistiques et multimodalit√©
:class: tip
:name: stats-multimodales
Le mod√®le de r√©gression est appliqu√© pour plusieurs modalit√©s de neuroimagerie. Dans cet exemple, on s'int√©resse √† la VBM. Mais le m√™me mod√®le fonctionne d√®s lors qu'on a une s√©rie de cartes pour diff√©rents sujets, et peut par exemple √™tre utilis√© en [IRMf](https://nilearn.github.io/auto_examples/05_glm_second_level/plot_oasis.html#sphx-glr-auto-examples-05-glm-second-level-plot-oasis-py) ou bien en TEP. Le m√™me type de mod√®le peut aussi s'appliquer √† des mesures prises sur des r√©cepteurs en imagerie optique, ou des mesures moyennes sur un faisceau de fibres en IRMd. Le mod√®le de r√©gression est partout!
```

## Mod√®le lin√©aire g√©n√©ral
```{code-cell} ipython 3
:tags: ["hide-input"]
from nilearn.plotting import plot_design_matrix
ax = plot_design_matrix(design_matrix)
ax.set_title('Second level design matrix', fontsize=12)
ax.set_ylabel('maps')
plt.tight_layout()
plt.show()                                                
```    
### Variables
Ici, on a une repr√©sentation diff√©rente. Cette repr√©sentation a l‚Äôavantage de permettre de voir plusieurs ¬´ courbes ¬ª simultan√©ment de mani√®re claire. En math√©matique, on appel ce type de repr√©sentation des ¬´ matrices ¬ª.

On a plusieurs tableaux dans cette repr√©sentation. Dans le premier, on a une seule colonne avec plein de lignes, ensuite on a un tableau qui a le m√™me nombre de lignes que le premier mais avec 4 colonnes et un dernier tableau avec seulement 3 lignes et une colonne. Dans les deux premiers tableaux, chaque ligne correspond √† un sujet et chaque colonne correspond √† un type de variable. Il faut pr√©ciser que l‚Äôon n‚Äôa pas pris le scan c√©r√©bral complet pour le premier tableau. En fait, on a pris le m√™me voxel chez tous les participants (√† l‚Äôaide d‚Äôun recalage).

Les tons de gris repr√©sentent en fait des valeurs num√©riques. Or, pour aider √† la visualisation, nous avons utilis√© une √©chelle de couleurs qui repr√©sente ces valeurs.

Le premier tableau repr√©sente les valeurs des cartes c√©r√©brales, qui sont les valeurs que l‚Äôon cherche √† expliquer. Les tableaux √† droite du ¬´ = ¬ª repr√©sentent les valeurs qui permettent d‚Äôexpliquer les valeurs des cartes c√©r√©brales.
Ici, on a deux vecteurs qui cotent pour le sexe de nos participants et un autre qui repr√©sente le score de d√©pression pour chacune de nos observations (dans le premier tableau).

Cette repr√©sentation est plut√¥t simple, nous avons une formule ressemblant √† y = mx+b, donnant une relation lin√©aire. √Ä gauche on a le y, c‚Äôest ce qu‚Äôon cherche √† mod√©liser. Le tableau √† droite, on a les param√®tres explicatifs. Pour le sexe, on a mis un 1 quand le sexe correspondait au sujet et un 0 lorsqu‚Äôil ne correspondait pas. Ainsi, on remarque que, ici, la moiti√© des sujets √©taient des hommes et l‚Äôautre moiti√© √©taient des femmes. La variable de d√©pression est mesur√©e √† l‚Äôaide de questionnaires et le score est repr√©sent√© ici dans la 3e colonne du 2e tableau. Le 3e tableau repr√©sente l‚Äôamplitude des diff√©rentes facteurs explicatifs que l‚Äôon peut changer afin de mieux expliquer nos valeurs IRMf. Ceci revient √† la m√™me chose qui a √©t√© vue dans les graphiques pr√©sent√©s plus t√¥t. Ainsi, le score que l‚Äôon tente d‚Äôexpliquer pour un sujet (une ligne) sera obtenu √† l‚Äôaide de la formule suivante : le score ¬´ homme ¬ª du sujet x le coefficient ¬´ homme ¬ª + le score ¬´ femme ¬ª du sujet x le coefficient ¬´ femme ¬ª + le score ¬´ d√©pression ¬ª du sujet x le coefficient ¬´ d√©pression ¬ª. Ce qui reste et qui n,est pas expliqu√© par cette formule correspondra aux r√©sidus. Tel que vu plus t√¥t, la formule avec les coefficients auront comme but de minimiser les r√©sidus le plus possible.

Ici, on a un exemple un peu plus complexe. √Ä gauche, on a ce qu‚Äôon vient de voir et au centre, on a s√©par√© le score de d√©pression pour les femmes et celui pour les hommes.

Dans l‚Äôexemple pr√©c√©dent, le coefficient de d√©pression √©tait le m√™me pour les hommes et les femmes. On pr√©tendait alors que le niveau d‚Äôinfluence de la d√©pression sur le cerveau des femmes et celui des hommes √©tait pareil. Dans le tableau du centre, nous attribuions un coefficient diff√©rent aux scores de d√©pression des hommes et celui des femmes, pr√©tendant alors que l‚Äôinfluence de la d√©pression sur le cerveau pourrait diff√©rer en fonction du sexe. Ici, on test alors le principe d‚Äôinteraction. En statistiques classiques, on pourrait comparer ce mod√®le a une ANOVA.

En r√©alit√©, ce mod√®le se nomme le mod√®le lin√©aire g√©n√©ral car on peut pas mal tout tester. Si on veut faire un test-t, on peut le faire √† l‚Äôaide de ce mod√®le.

Si on prend deux coefficients de notre mod√®le, on peut regarder la diff√©rence entre ces deux coefficients. Par exemple, on peut regarder si l‚Äôinfluence de la d√©pression sur le cerveau chez les femmes (√ü1) diff√®re de celle de la d√©pression sur le cerveau chez les hommes (√ü2).

Ca donnerait quelque chose comme √ßa et nous donnerait une carte de contraste statistique qui nous permet de contraster l‚Äôinfluence de la d√©pression chez les femmes et chez les hommes.
Ce qui va changer d‚Äôun voxel √† l‚Äôautre ce n‚Äôest pas les facteurs explicatifs, ce sont les y (les mesures d‚Äôactivation). On n‚Äôaura ainsi pas les m√™mes b√™tas et les m√™mes valeurs de contraste. C‚Äôest aussi appel√© une approche massivement univari√©e.

On peut parler d‚Äôune analyse de niveau 1 pour les analyses individuelles et les analyses de niveau 2 pour les analyses de groupe.

## Conclusion

En g√©n√©rale quand on parle de l‚ÄôIRMf ou m√™me de la VBM, on trouve des blobs qui pr√©sentent des effets significatifs. Ce qui est important de se rappeler est toute la s√©rie d‚Äô√©tapes qui m√®nent √† ce type de carte.
1. La premi√®re, l‚Äôhypoth√®se psychologique : 	On avait commenc√© le cours avec ces deux t√¢ches avec les visages qui expriment les √©motions et des stimuli contr√¥les. Notre est hypoth√®se est que ce sont les visages qui expliquent le patron d‚Äôactivation observ√©.  
2. Ensuite, on a des hypoth√®ses au niveau neuronal : On √©met des hypoth√®ses au sujet du type de r√©ponse neuronale observ√©. En IRMf, on √©met l‚Äôhypoth√®se que l‚Äôactivation atteint son plafond quand la stimulation est d√©but√©e et qu‚Äôelle retombe √† 0 une fois le bloc termin√©.
3. Finalement, on a des hypoth√®ses h√©modynamiques : On va supposer que l‚Äôactivit√© BOLD enregistr√©e en IRMf va correspondre √† l‚Äôactivit√© neuronale.

√Ä la fin, on aura des √©tapes d‚Äôanalyses d‚Äôimages, de recalage, de d√©bruitage et de mod√©lisation statistique.

Ainsi, il y a beaucoup de choses, de choix et d‚Äôhypoth√®ses qui vont derri√®re ce petit blob rouge qui ressort dans des cartes statistiques.
