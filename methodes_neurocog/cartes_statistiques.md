---
jupytext:
  cell_metadata_filter: -all
  formats: md:myst
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.10.3
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---
(cartes-statistiques-chapitre)=
# Cartes statistiques

<table>
  <tr>
    <td align="center">
      <a href="https://github.com/elisabethloranger">
        <img src="https://avatars.githubusercontent.com/u/90270981?v=4?s=100" width="100px;" alt=""/>
        <br /><sub><b>√âlisabeth Loranger</b></sub>
      </a>
      <br />
        <a title="Contenu">ü§î</a>
    </td>
    <td align="center">
      <a href="https://github.com/pbellec">
        <img src="https://avatars.githubusercontent.com/u/1670887?v=4?s=100" width="100px;" alt=""/>
        <br /><sub><b>Pierre bellec</b></sub>
      </a>
      <br />
        <a title="Contenu">ü§î</a>
    </td>
  </tr>
</table>

```{warning}
Ce chapitre est en cours de d√©veloppement. Il se peut que l'information soit incompl√®te, ou sujette √† changement.
```
## Objectifs du cours

Dans ce chapitre, il sera question de l'utilisation du mod√®le de r√©gression pour g√©n√©rer des cartes statistiques c√©r√©brales de groupe. Les statistiques de groupe permettent de combiner les mesures du cerveau de plusieurs individus et ainsi de contraster des groupes (ex. groupe de personnes jeunes et groupe de personnes √¢g√©es) ou bien de tester l'association avec une variable continue (ex. l'√¢ge).

Les objectifs sp√©cifiques du cours portent sur les concepts suivants :
 * la r√©gression lin√©aire
 * le mod√®le lin√©aire g√©n√©ral
 * les comparaisons multiples

## R√©gression lin√©aire

### Variables
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
# Importer les librairies
import numpy as np
import matplotlib.pyplot as plt
from nilearn import datasets
from nilearn.input_data import NiftiMasker
from nilearn.image import get_data

# Charger les donn√©es
n_subjects = 100  
oasis_dataset = datasets.fetch_oasis_vbm(n_subjects=n_subjects)
gray_matter_map_filenames = oasis_dataset.gray_matter_maps
age = oasis_dataset.ext_vars['age'].astype(float)
sex = oasis_dataset.ext_vars['mf'] == b'F'

# Conversion des donn√©es en pandas dataframe
# Deux voxels int√©ressants ont √©t√© s√©lectionn√©s
import pandas as pd
coords = np.array([[ 29.,  10.,   4.], [-19.,   8., -11.]])
colors = ['blue', 'olive']

from nilearn import input_data
masker = input_data.NiftiSpheresMasker(coords)
gm = masker.fit_transform(gray_matter_map_filenames)
subject_label = [f'sub-{num}' for num in range(n_subjects)]
df = pd.DataFrame({
    "subject_label": subject_label,
    "age": age,
    "sexe": oasis_dataset.ext_vars['mf'],
    "MG1": gm[:, 0],
    "MG2": gm[:, 1]
    })

df["sexe"] = df["sexe"].replace([b'F', b'M'], value=['femelle', 'male'])

# On g√©n√®re la Figure
from nilearn import plotting
import seaborn as sns
fig = plt.figure(figsize=(24, 14))

for i in range(0, 6):        
    nx = np.floor_divide(i, 3)
    ny = np.remainder(i, 3)
    ax = plt.subplot2grid((2, 5), (nx, ny), colspan=1)
    roi_img = plotting.plot_anat(
        gray_matter_map_filenames[i], cut_coords=[coords[nx][2]], figure=fig,
        axes=ax, display_mode='z', colorbar=False)
    roi_img.add_markers([coords[nx]], colors[nx], 100)

sns.set_theme(style="darkgrid")
ax = plt.subplot2grid((2, 5), (0, 3), colspan=2)
sns.histplot(
    df["MG1"], ax=ax, binwidth=0.05, binrange=[0, 1], stat='frequency')

ax = plt.subplot2grid((2, 5), (1, 3), colspan=2)
sns.histplot(
    df["MG2"], ax=ax, binwidth=0.05, binrange=[0, 1], stat='frequency')

from myst_nb import glue
glue("vbm-distribution-fig", fig, display=False)
```
```{glue:figure} vbm-distribution-fig
:figwidth: 800px
:name: vbm-distribution-fig
La position de deux voxels (illustr√©e √† l'aide d'un cercle bleu (haut) et d'un cercle olive (bas)) est ici superpos√©e sur des cartes de densit√© de mati√®re grise pour diff√©rents sujets du jeu de donn√©es OASIS ([Marcus et al., 2010](https://dx.doi.org/10.1162%2Fjocn.2009.21407)). √Ä droite, un histograme repr√©sente la distribution de la densit√© de mati√®re grise pour le voxel correspondant, √† travers un √©chantillon de 100 sujets. Cette figure est adapt√©e d'un tutoriel de la librairie [nilearn](https://nilearn.github.io/auto_examples/05_glm_second_level/plot_oasis.html#sphx-glr-auto-examples-05-glm-second-level-plot-oasis-py) (cliquer sur + pour voir le code). Cette figure est distribu√©e sous license [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```
Les concepts pr√©sent√©s dans ce chapitre s‚Äôappliquent √† la plupart des modalit√©s d'imagerie vues dans le cours de fa√ßon plus ou moins identique. Afin de rendre les choses un peu plus concr√®tes, nous allons ici nous int√©resser √† une analyse morphom√©trique de type VBM (IRM structurelle). Cette analyse utilise le jeu de donn√©es OASIS ([Marcus et al., 2010](https://dx.doi.org/10.1162%2Fjocn.2009.21407)). Des cartes de densit√© de mati√®re grise pour les donn√©es OASIS sont disponibles via la librairie [nilearn](https://nilearn.github.io/modules/generated/nilearn.datasets.fetch_oasis_vbm.html). Pour chaque voxel, on dispose d'une mesure locale de densit√© de mati√®re grise qui varie entre 0 et 1. Comme toutes les images des 100 participants OASIS utilis√©s dans cet exemple ont √©t√© recal√©es dans un m√™me espace st√©r√©otaxique, chaque voxel est associ√© √† une s√©rie de 100 mesures. Il s'agit de notre **variable d√©pendante**. On va par la suite chercher √† expliquer les variations de cette mesure √† travers les sujets √† l'aide d'autres variables, appel√©es les **pr√©dicteurs**. Pour notre exemple, nous allons d√©marrer avec l'√¢ge des participants qui varie ici de 20 ans √† 90 ans.

### Mod√®le lin√©aire
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
# On r√©organise le DataFrame pour utiliser seaborn
df2 = df.melt(id_vars=["age", "sexe"], value_vars=["MG1", "MG2"], value_name="MG")
fig = sns.lmplot(x="age", y="MG", data=df2, col='variable',
           ci=None, scatter_kws={"s": 50, "alpha": 1})

# On colle la figure dans le jupyter book
from myst_nb import glue
glue("regression-vbm-fig", fig.fig, display=False)           
```
```{glue:figure} regression-vbm-fig
:figwidth: 800px
:name: regression-vbm-fig
Exemple de r√©gression lin√©aire o√π la variable d√©pendante est la densit√© de mati√®re grise pour un voxel et le pr√©dicteur est l'√¢ge. Les valeurs de densit√© de mati√®re grise proviennent de 100 sujets de la base de donn√©es OASIS ([Marcus et al., 2010](https://dx.doi.org/10.1162%2Fjocn.2009.21407)). Les deux voxels utilis√©s ici sont les m√™mes que ceux repr√©sent√©s dans la {numref}`vbm-distribution-fig` (voxel bleu √† gauche, voxel olive √† droite). La r√©gression lin√©aire est r√©alis√©e √† l'aide de la libraire [seaborn](https://seaborn.pydata.org) (cliquer sur + pour voir le code). Cette figure est distribu√©e sous license [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```
Le concept soutenant le mod√®le de r√©gression est une √©quation, ou une sorte de loi, qui va tenter de pr√©dire la variable d√©pendante (ici, la densit√© de mati√®re grise) √† partir de pr√©dicteurs (par exemple, l'√¢ge). Mais contrairement √† une loi physique qui tente de repr√©senter une d√©pendance exacte (jusqu'√† un certain degr√©), la pr√©sente loi ne capture qu'une fraction de la variance de notre mesure. La loi va donc incorporer un certain bruit repr√©sentant toutes les sources de variabilit√© que l'on ne peut pas capturer avec notre relation. La relation math√©matique va prendre la forme suivante:

`densite_matiere_grise = b0 + b1 * age + e`

O√π

 * `densite_matiere_grise` est la densit√© de mati√®re grise mesur√©e pour un voxel
 * `age` est l'√¢ge du participant de recherche
 * `b0` est une valeur constante, appel√©e en anglais "intercept" (l'ordonn√©e √† l'origine). Cette valeur est identique pour tous les sujets. Dans ce cas-ci, elle repr√©senterait la densit√© de mati√®re grise observ√©e √† la naissance (`age=0`), en moyenne sur la population.
 * `b1` est une autre constante qui dans cet exemple mesure la r√©duction de mati√®re grise par ann√©e de vie (en moyenne sur la population).
 * `e` est un bruit de mesure qui capture toutes les variations de `densite_matiere_grise` que l'on ne peut pas expliquer avec `age`. Typiquement, on suppose que la moyenne de `e` dans la population est `0` et que la variance de `e` est identique pour tous les sujets, √©gale √† $\sigma^2$.

On ne connait √©videmment pas les coefficients `b0` et `b1`. Il sera n√©cessaire d'utiliser une proc√©dure statistique pour les `estimer`, c'est √† dire deviner (au mieux) leurs valeurs √† partir des donn√©es dont nous disposons. Par exemple, pour la r√©gion de couleur `olive` (graphe de droite dans {numref}`regression-vbm-fig`), on voit que l'on perd environ 25% de densit√© entre 20 ans et 90 ans (voir {numref}`regression-vbm-fig`). On perd donc environ 0.35% de densit√© de mati√®re grise par an, soit `b1 ~ -0.0035`. En utilisant cette valeur et en remarquant que la densit√© de mati√®re grise est d'√† peu pr√®s `0.85` √† `20` ans, on en d√©duit que la densit√© √† la naissance devrait √™tre `b0=0.92`. En pratique, la proc√©dure statistique va choisir les valeurs `b0` et `b1` pour minimiser l'amplitude des r√©sidus de la r√©gression:

`residus = densite_matiere_grise - b0 - b1 * age`

Une fois les coefficients `b0` et `b1` estim√©s, on peut tracer une droite qui repr√©sente les valeurs de densit√© de mati√®re grise pr√©dites √† partir de l'√¢ge des sujets (voir {numref}`regression-vbm-fig`). Si le mod√®le permet d'expliquer une partie importante de la variabilit√© de la variable d√©pendante, les points mesur√©s seront proches de la droite de pr√©diction.

### Analyse massivement univari√©e
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
from nilearn.glm.second_level import make_second_level_design_matrix
design_df = df[["subject_label", "age"]].replace(['femelle', 'male'], value=[0, 1])
design_matrix = make_second_level_design_matrix(
    subject_label,
    design_df
    )
from nilearn.glm.second_level import SecondLevelModel
second_level_model = SecondLevelModel(smoothing_fwhm=5.0)
second_level_model = second_level_model.fit(gray_matter_map_filenames,
                                            design_matrix=design_matrix)
beta0 = second_level_model.compute_contrast(second_level_contrast="intercept", output_type="effect_size")
beta1 = second_level_model.compute_contrast(second_level_contrast="age", output_type="effect_size")

# On g√©n√®re la Figure
from nilearn import plotting
import seaborn as sns
fig = plt.figure(figsize=(24, 14))

ax = plt.subplot2grid((2, 4), (0, 0), colspan=3)
roi_img = plotting.plot_stat_map(
    beta0, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='intercept (b0)')
roi_img.add_markers([coords[1]], colors[1], 100)

ax = plt.subplot2grid((2, 4), (1, 0), colspan=3)
roi_img = plotting.plot_stat_map(
    beta1, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='effet de l\'age (b1)')
roi_img.add_markers([coords[1]], colors[1], 100)

# On colle la figure dans le jupyter book
from myst_nb import glue
glue("b0-b1-fig", fig, display=False)           
```
```{glue:figure} b0-b1-fig
:figwidth: 600px
:name: b0-b1-fig
Cartes de param√®tres statistiques dans une r√©gression lin√©aire massivement univari√©e. Premi√®re ligne: intercept `b0`, deuxi√®me ligne: effet lin√©aire de l'√¢ge `b1`. Cette figure est adapt√©e d'un tutoriel de la librairie [nilearn](https://nilearn.github.io/auto_examples/05_glm_second_level/plot_oasis.html#sphx-glr-auto-examples-05-glm-second-level-plot-oasis-py) (cliquer sur + pour voir le code). Cette figure est distribu√©e sous license [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```
Pour l'instant, nous avons utilis√© un mod√®le de r√©gression pour deux voxels seulement. Mais une carte VBM peut inclure des centaines de milliers de voxels. Les logiciels de neuroimagerie permettent d'effectuer syst√©matiquement une r√©gression lin√©aire pour l'ensemble des voxels, simultan√©ment. Dans ce cas, on estime deux param√®tres pour chaque voxel: `b0` (l'intercept) et `b1` (l'effet de l'√¢ge). On va donc g√©n√©rer deux cartes statistiques s√©par√©es (voir {numref}`b0-b1-fig`). Ces deux cartes r√©capitulent donc des milliers de mod√®les de r√©gression diff√©rents. Comme les r√©gressions effectu√©es √† chaque voxel sont ind√©pendantes les unes des autres, on parle de mod√®le univari√©. L'autre option, le mod√®le multivari√©, chercherait plut√¥t √† combiner les valeurs obtenues √† diff√©rents voxels. De plus, comme on fait un tr√®s grand nombre de r√©gressions en m√™me temps, on parle de r√©gression **massivement univari√©e**.

```{admonition} Statistiques et multimodalit√©
:class: tip
:name: stats-multimodales
Le mod√®le de r√©gression est appliqu√© √† plusieurs modalit√©s de neuroimagerie. Dans ce chapitre, il est question d'un exemple utilisant la VBM. Mais le m√™me mod√®le fonctionne d√®s lors qu'on a une s√©rie de cartes pour diff√©rents sujets. Il pourrait par exemple √™tre utilis√© en [IRMf](https://nilearn.github.io/auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html#sphx-glr-auto-examples-05-glm-second-level-plot-second-level-one-sample-test-py) ou bien en TEP. Le m√™me type de mod√®le peut aussi s'appliquer √† des mesures prises sur des r√©cepteurs en imagerie optique ou des mesures moyennes sur un faisceau de fibres en IRMd. Le mod√®le de r√©gression est partout!
```

## Mod√®le lin√©aire g√©n√©ral

### Variables
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
sns.set_theme(style="ticks")

# Show the joint distribution using kernel density estimation
fig = sns.jointplot(
    data=df,
    x="age", y="MG1", hue="sexe",
    kind="scatter",
)

# On colle la figure dans le jupyter book
from myst_nb import glue
glue("age-sexe-fig", fig.fig, display=False)           
```
```{glue:figure} age-sexe-fig
:figwidth: 600px
:name: age-sexe-fig
 Relation entre √¢ge, sexe et densit√© de mati√®re grise pour un voxel (le voxel de couleur bleu dans {numref}`vbm-distribution-fig`). Le graphique est r√©alis√© √† l'aide de la libraire [seaborn](https://seaborn.pydata.org) (cliquer sur + pour voir le code). Cette figure est distribu√©e sous license [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```

L'approche de r√©gression lin√©aire que l'on vient de voir est simple et puissante, mais elle est limit√©e √† deux variables. En neurosciences humaines, on ne se trouvera g√©n√©ralement pas dans ce cas. On va tr√®s souvent vouloir √©tudier des facteurs multiples de mani√®re conjointe. M√™me si la repr√©sentation du sexe des participants par une variable binaire est [tr√®s (tr√®s) simplificatrice](https://blogs.scientificamerican.com/sa-visual/visualizing-sex-as-a-spectrum/) - sans compter la diversit√© de l'identit√© de genre, nous allons quand m√™me essayer d'int√©grer le sexe (male vs femelle) dans notre analyse. La figure ci-dessous montre les distributions d'√¢ge et de mati√®re grise (pour le voxel bleu), s√©par√©es par sexe. Ce graphique sugg√®re que la distribution de mati√®re grise est peut-√™tre diff√©rente entre male et femelle, mais cette diff√©rence pourrait √©galement √™tre li√©e √† l'√¢ge. Le mod√®le lin√©aire g√©n√©ral nous permet d'int√©grer toutes ces variables dans une seule analyse.

### R√©gression multiple
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
from nilearn.plotting import plot_design_matrix
design_df = df[["subject_label", "age", "sexe"]].replace(['femelle', 'male'], value=[0, 1])
design_matrix = make_second_level_design_matrix(
    subject_label,
    design_df
    )
fig, ax = plt.subplots(ncols=5, figsize=(6, 12), sharey=True)
Y = df["MG1"].to_numpy()
X = design_matrix.to_numpy()
ax[0].plot(np.expand_dims(Y, axis=1), range(len(Y)))
ax[1].plot(X[:,0], range(len(Y)))
ax[2].plot(X[:,1], range(len(Y)))
ax[3].plot(X[:,2], range(len(Y)))
ax[0].set_ylabel('# sujet', fontsize=18)
ax[0].set_title('MG', fontsize=20)
ax[1].set_title('√Çge', fontsize=20)
ax[2].set_title('Sexe', fontsize=20)
ax[3].set_title('Intercept', fontsize=20)
plot_design_matrix(design_matrix, ax=ax[4])
ax[4].set_title('Matrice de dessein', fontsize=12)
ax[4].set_ylabel('# sujet')
plt.gca().invert_yaxis()
plt.tight_layout()

# On colle la figure dans le jupyter book
from myst_nb import glue
glue("design-matrix-fig", fig, display=False)           
```
```{glue:figure} design-matrix-fig
:figwidth: 600px
:name: design-matrix-fig
 Variables pour une r√©gression multiple. La variable d√©pendante est la densit√© de mati√®re grise pour un voxel (GM, le voxel de couleur bleu dans {numref}`vbm-distribution-fig`). Les autres colonnes repr√©sentent les variations de l'√¢ge, du sexe et de l'intercept au travers des sujets (variables pr√©dictives). Les variables pr√©dictives sont g√©n√©ralement repr√©sent√©es de mani√®re plus compacte, sous la forme d'une image o√π la couleur de chaque pixel repr√©sente l'intensit√© du r√©gresseur. Le graphique est adapt√© d'un [code python](https://dartbrains.org/content/GLM.html) par l'√©quipe Dartbrains, ainsi que d'un [tutoriel nilearn](https://nilearn.github.io/glm/first_level_model.html) (cliquer sur + pour voir le code). Cette figure est distribu√©e sous license [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```

D'un point de vue math√©matique, le mod√®le de r√©gression multiple, parfois appel√© mod√®le lin√©aire g√©n√©ral, consiste simplement √† incorporer plus de variables dans la "loi" qui pr√©dit la variable d√©pendante √† partir des r√©gresseurs:
`densite_matiere_grise = b0 + b1 * age + b2 * sexe + e`

Le seul nouveau coefficient est `b2`, qui dans ce cas mesure la diff√©rence entre la moyenne de mati√®re grise entre les femelles (cod√©es avec un 0 dans le mod√®le) et les males (cod√©s avec un 1 dans le mod√®le), **apr√®s ajustement pour l'√¢ge des sujets**. Ce type de codage pour donn√©es cat√©gorielles est appel√© "dummy variable" en anglais, et permet d'int√©grer des tests de diff√©rences de moyenne entre groupe dans un mod√®le de r√©gression.

```{admonition} R√©gression multiple et statistiques classiques
:class: tip
:name: stats-regression
Le mod√®le de r√©gression multiple est tr√®s flexible. Il est possible de formuler la plupart des tests classiques, tels que l'analyse de variance (ANOVA) ou bien le test d'√©galit√© des moyennes de Student (t-test) √† l'aide du mod√®le de r√©gression lin√©aire. Voir ce [guide](https://lindeloev.github.io/tests-as-linear/) pour plus de d√©tails.
```

### Cartes statistiques
```{code-cell} ipython 3
:tags: ["hide-input", "remove-output"]
second_level_model = SecondLevelModel(smoothing_fwhm=5.0)
second_level_model = second_level_model.fit(gray_matter_map_filenames,
                                            design_matrix=design_matrix)
beta0 = second_level_model.compute_contrast(second_level_contrast="intercept", output_type="effect_size")
beta1 = second_level_model.compute_contrast(second_level_contrast="age", output_type="effect_size")
beta2 = second_level_model.compute_contrast(second_level_contrast="sexe", output_type="effect_size")

# On g√©n√®re la Figure
from nilearn import plotting
import seaborn as sns
fig = plt.figure(figsize=(24, 14))

ax = plt.subplot2grid((2, 4), (0, 0), colspan=2)
roi_img = plotting.plot_stat_map(
    beta0, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='intercept (b0)')
roi_img.add_markers([coords[1]], colors[1], 100)

ax = plt.subplot2grid((2, 4), (0, 2), colspan=2)
roi_img = plotting.plot_stat_map(
    beta1, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='effet de l\'age (b1)')
roi_img.add_markers([coords[1]], colors[1], 100)

ax = plt.subplot2grid((2, 4), (1, 0), colspan=2)
roi_img = plotting.plot_stat_map(
    beta2, bg_img=gray_matter_map_filenames[0], cut_coords=coords[1], figure=fig,
    axes=ax, display_mode='ortho', colorbar=True, title='effet du sexe (b2)')
roi_img.add_markers([coords[1]], colors[1], 100)

# On colle la figure dans le jupyter book
from myst_nb import glue
glue("multi-regression-fig", fig, display=False)           
```
```{glue:figure} multi-regression-fig
:figwidth: 800px
:name: multi-regression-fig
 Cartes de param√®tres statistiques dans une r√©gression lin√©aire multiple massivement univari√©e. Haut gauche: intercept `b0`, haut droite: effet lin√©aire de l'√¢ge `b1`, bas gauche: effet lin√©aire du sexe `b2`. Cette figure est adapt√©e d'un tutoriel de la librairie [nilearn](https://nilearn.github.io/auto_examples/05_glm_second_level/plot_oasis.html#sphx-glr-auto-examples-05-glm-second-level-plot-oasis-py) (cliquer sur + pour voir le code). Cette figure est distribu√©e sous license [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).
```

Une caract√©ristique un peu contre-intuitive avec la r√©gression multiple est que la carte d'effet de l'√¢ge est diff√©rente de la section avec la r√©gression simple. En effet, l'effet de l'√¢ge est maintenant √©valu√© _apr√®s avoir pris en compte des diff√©rences de sexe_. Malgr√© cela, le r√©sultat de la r√©gression n'a pas chang√© de mani√®re frappante: le cortex s'atrophie avec l'√¢ge (en bleu), alors que le liquide c√©phalo-rachidien s'√©tend ce qui apparait comme une expansion de la mati√®re grise √† cause des effets de volume partiel (en rouge). L'analyse sur la variable de `sexe` montre que la densit√© de mati√®re grise est plus √©lev√©e (en moyenne) dans le cortex chez les hommes, alors que la tendance est invers√©e au niveau du cervelet.

## Tests statistiques

### Tests t et valeur p

### Comparaisons multiples

### Correction de Bonferroni

## Conclusion

En g√©n√©rale quand on parle de l‚ÄôIRMf ou m√™me de la VBM, on trouve des blobs qui pr√©sentent des effets significatifs. Ce qui est important de se rappeler est toute la s√©rie d‚Äô√©tapes qui m√®nent √† ce type de carte.
1. La premi√®re, l‚Äôhypoth√®se psychologique : 	On avait commenc√© le cours avec ces deux t√¢ches avec les visages qui expriment les √©motions et des stimuli contr√¥les. Notre est hypoth√®se est que ce sont les visages qui expliquent le patron d‚Äôactivation observ√©.  
2. Ensuite, on a des hypoth√®ses au niveau neuronal : On √©met des hypoth√®ses au sujet du type de r√©ponse neuronale observ√©. En IRMf, on √©met l‚Äôhypoth√®se que l‚Äôactivation atteint son plafond quand la stimulation est d√©but√©e et qu‚Äôelle retombe √† 0 une fois le bloc termin√©.
3. Finalement, on a des hypoth√®ses h√©modynamiques : On va supposer que l‚Äôactivit√© BOLD enregistr√©e en IRMf va correspondre √† l‚Äôactivit√© neuronale.

√Ä la fin, on aura des √©tapes d‚Äôanalyses d‚Äôimages, de recalage, de d√©bruitage et de mod√©lisation statistique.

Ainsi, il y a beaucoup de choses, de choix et d‚Äôhypoth√®ses qui vont derri√®re ce petit blob rouge qui ressort dans des cartes statistiques.
